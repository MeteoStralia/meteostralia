{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier, RidgeClassifierCV, SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler, CondensedNearestNeighbour\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_Location', 'id_Date', 'Date', 'Location', 'MinTemp', 'MaxTemp',\n",
       "       'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm',\n",
       "       'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Temp9am',\n",
       "       'Temp3pm', 'RainToday', 'RainTomorrow', 'WindGustDir_cos',\n",
       "       'WindGustDir_sin', 'WindDir9am_cos', 'WindDir9am_sin', 'WindDir3pm_cos',\n",
       "       'WindDir3pm_sin', 'Month_cos', 'Month_sin', 'Season_cos', 'Season_sin',\n",
       "       'Climate_Desert', 'Climate_Grassland', 'Climate_Subtropical',\n",
       "       'Climate_Temperate', 'Climate_Tropical', 'Year_2007', 'Year_2008',\n",
       "       'Year_2009', 'Year_2010', 'Year_2011', 'Year_2012', 'Year_2013',\n",
       "       'Year_2014', 'Year_2015', 'Year_2016', 'Year_2017'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data_saved/df_final.csv')\n",
    "df_gps = pd.read_csv('../data/cities_coordinates_gps.csv', index_col = 0).T\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RainTomorrow\n",
       "0.0    0.778709\n",
       "1.0    0.221291\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RainTomorrow'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135600 entries, 0 to 135599\n",
      "Data columns (total 44 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id_Location          135600 non-null  object \n",
      " 1   id_Date              135600 non-null  object \n",
      " 2   Date                 135600 non-null  object \n",
      " 3   Location             135600 non-null  object \n",
      " 4   MinTemp              135600 non-null  float64\n",
      " 5   MaxTemp              135600 non-null  float64\n",
      " 6   Rainfall             135600 non-null  float64\n",
      " 7   WindGustSpeed        135600 non-null  float64\n",
      " 8   WindSpeed9am         135600 non-null  float64\n",
      " 9   WindSpeed3pm         135600 non-null  float64\n",
      " 10  Humidity9am          135600 non-null  float64\n",
      " 11  Humidity3pm          135600 non-null  float64\n",
      " 12  Pressure9am          135600 non-null  float64\n",
      " 13  Pressure3pm          135600 non-null  float64\n",
      " 14  Temp9am              135600 non-null  float64\n",
      " 15  Temp3pm              135600 non-null  float64\n",
      " 16  RainToday            135600 non-null  float64\n",
      " 17  RainTomorrow         135600 non-null  float64\n",
      " 18  WindGustDir_cos      135600 non-null  float64\n",
      " 19  WindGustDir_sin      135600 non-null  float64\n",
      " 20  WindDir9am_cos       135600 non-null  float64\n",
      " 21  WindDir9am_sin       135600 non-null  float64\n",
      " 22  WindDir3pm_cos       135600 non-null  float64\n",
      " 23  WindDir3pm_sin       135600 non-null  float64\n",
      " 24  Month_cos            135600 non-null  float64\n",
      " 25  Month_sin            135600 non-null  float64\n",
      " 26  Season_cos           135600 non-null  float64\n",
      " 27  Season_sin           135600 non-null  float64\n",
      " 28  Climate_Desert       135600 non-null  int64  \n",
      " 29  Climate_Grassland    135600 non-null  int64  \n",
      " 30  Climate_Subtropical  135600 non-null  int64  \n",
      " 31  Climate_Temperate    135600 non-null  int64  \n",
      " 32  Climate_Tropical     135600 non-null  int64  \n",
      " 33  Year_2007            135600 non-null  int64  \n",
      " 34  Year_2008            135600 non-null  int64  \n",
      " 35  Year_2009            135600 non-null  int64  \n",
      " 36  Year_2010            135600 non-null  int64  \n",
      " 37  Year_2011            135600 non-null  int64  \n",
      " 38  Year_2012            135600 non-null  int64  \n",
      " 39  Year_2013            135600 non-null  int64  \n",
      " 40  Year_2014            135600 non-null  int64  \n",
      " 41  Year_2015            135600 non-null  int64  \n",
      " 42  Year_2016            135600 non-null  int64  \n",
      " 43  Year_2017            135600 non-null  int64  \n",
      "dtypes: float64(24), int64(16), object(4)\n",
      "memory usage: 45.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encodage des locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gps_lat'] = df['Location'].map(lambda x : df_gps.loc[x, 'lat'])\n",
    "df['gps_lon'] = df['Location'].map(lambda x : df_gps.loc[x, 'long'])\n",
    "\n",
    "df['sin_lat'] = df['gps_lat'].apply(lambda x : np.sin(np.radians(x)))\n",
    "df['cos_lat'] = df['gps_lat'].apply(lambda x : np.cos(np.radians(x)))\n",
    "\n",
    "df['sin_lon'] = df['gps_lon'].apply(lambda x : np.round(np.sin(np.radians(x)), 6))\n",
    "df['cos_lon'] = df['gps_lon'].apply(lambda x : np.round(np.cos(np.radians(x)), 6))\n",
    "\n",
    "df = df.drop(columns = ['id_Location', 'gps_lat', 'gps_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_Date</th>\n",
       "      <th>Date</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Year_2012</th>\n",
       "      <th>Year_2013</th>\n",
       "      <th>Year_2014</th>\n",
       "      <th>Year_2015</th>\n",
       "      <th>Year_2016</th>\n",
       "      <th>Year_2017</th>\n",
       "      <th>sin_lat</th>\n",
       "      <th>cos_lat</th>\n",
       "      <th>sin_lon</th>\n",
       "      <th>cos_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-07-01</td>\n",
       "      <td>2008-07-01</td>\n",
       "      <td>8.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.572554</td>\n",
       "      <td>0.819867</td>\n",
       "      <td>0.661303</td>\n",
       "      <td>-0.750119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-02</td>\n",
       "      <td>2008-07-02</td>\n",
       "      <td>12.7</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.572554</td>\n",
       "      <td>0.819867</td>\n",
       "      <td>0.661303</td>\n",
       "      <td>-0.750119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-07-03</td>\n",
       "      <td>2008-07-03</td>\n",
       "      <td>6.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.572554</td>\n",
       "      <td>0.819867</td>\n",
       "      <td>0.661303</td>\n",
       "      <td>-0.750119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-04</td>\n",
       "      <td>2008-07-04</td>\n",
       "      <td>5.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.572554</td>\n",
       "      <td>0.819867</td>\n",
       "      <td>0.661303</td>\n",
       "      <td>-0.750119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-07</td>\n",
       "      <td>2008-07-07</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.572554</td>\n",
       "      <td>0.819867</td>\n",
       "      <td>0.661303</td>\n",
       "      <td>-0.750119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_Date        Date  MinTemp  MaxTemp  Rainfall  WindGustSpeed  \\\n",
       "0  2008-07-01  2008-07-01      8.8     15.7       5.0           48.0   \n",
       "1  2008-07-02  2008-07-02     12.7     15.8       0.8           35.0   \n",
       "2  2008-07-03  2008-07-03      6.2     15.1       0.0           20.0   \n",
       "3  2008-07-04  2008-07-04      5.3     15.9       0.0           30.0   \n",
       "4  2008-07-07  2008-07-07      7.6     11.2      16.2           46.0   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  Year_2012  \\\n",
       "0          13.0          15.0         92.0         67.0  ...          0   \n",
       "1          13.0          15.0         75.0         52.0  ...          0   \n",
       "2           2.0          11.0         81.0         56.0  ...          0   \n",
       "3           6.0          13.0         71.0         46.0  ...          0   \n",
       "4          17.0          13.0         83.0         88.0  ...          0   \n",
       "\n",
       "   Year_2013  Year_2014  Year_2015  Year_2016  Year_2017   sin_lat   cos_lat  \\\n",
       "0          0          0          0          0          0 -0.572554  0.819867   \n",
       "1          0          0          0          0          0 -0.572554  0.819867   \n",
       "2          0          0          0          0          0 -0.572554  0.819867   \n",
       "3          0          0          0          0          0 -0.572554  0.819867   \n",
       "4          0          0          0          0          0 -0.572554  0.819867   \n",
       "\n",
       "    sin_lon   cos_lon  \n",
       "0  0.661303 -0.750119  \n",
       "1  0.661303 -0.750119  \n",
       "2  0.661303 -0.750119  \n",
       "3  0.661303 -0.750119  \n",
       "4  0.661303 -0.750119  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['id_Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - modelisation simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'RainTomorrow')\n",
    "y = df['RainTomorrow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - tres simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8478982300884956\n",
      "\n",
      "f1 score :  0.5855520948457752\n",
      "roc-auc score :  0.7194746831985506\n",
      "[[20081  1106]\n",
      " [ 3019  2914]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     21187\n",
      "         1.0       0.72      0.49      0.59      5933\n",
      "\n",
      "    accuracy                           0.85     27120\n",
      "   macro avg       0.80      0.72      0.75     27120\n",
      "weighted avg       0.84      0.85      0.84     27120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/.pyenv/versions/3.10.6/envs/meteo-venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - tres simple avec stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8476401179941003\n",
      "\n",
      "f1 score :  0.5931469082315872\n",
      "roc-auc score :  0.7238972332522922\n",
      "[[19976  1143]\n",
      " [ 2989  3012]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     21119\n",
      "         1.0       0.72      0.50      0.59      6001\n",
      "\n",
      "    accuracy                           0.85     27120\n",
      "   macro avg       0.80      0.72      0.75     27120\n",
      "weighted avg       0.84      0.85      0.84     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c - avec mise à l'echelle [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.846976401179941\n",
      "\n",
      "f1 score :  0.5917765099350777\n",
      "roc-auc score :  0.7232325003774212\n",
      "[[19962  1157]\n",
      " [ 2993  3008]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     21119\n",
      "         1.0       0.72      0.50      0.59      6001\n",
      "\n",
      "    accuracy                           0.85     27120\n",
      "   macro avg       0.80      0.72      0.75     27120\n",
      "weighted avg       0.84      0.85      0.84     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d - avec standardscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8474926253687316\n",
      "\n",
      "f1 score :  0.5929935052155088\n",
      "roc-auc score :  0.723862175881967\n",
      "[[19971  1148]\n",
      " [ 2988  3013]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     21119\n",
      "         1.0       0.72      0.50      0.59      6001\n",
      "\n",
      "    accuracy                           0.85     27120\n",
      "   macro avg       0.80      0.72      0.75     27120\n",
      "weighted avg       0.84      0.85      0.84     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8471976401179941\n",
      "\n",
      "f1 score :  0.5921259842519685\n",
      "roc-auc score :  0.723374552557922\n",
      "[[19968  1151]\n",
      " [ 2993  3008]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     21119\n",
      "         1.0       0.72      0.50      0.59      6001\n",
      "\n",
      "    accuracy                           0.85     27120\n",
      "   macro avg       0.80      0.72      0.75     27120\n",
      "weighted avg       0.84      0.85      0.84     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion 1 : je continue avec un minmaxscaler [-1, 1], augmenter le nom d'iter ne sert à rien, je garde straify = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Re *Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 16:14:45.058979: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-17 16:14:45.341454: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-17 16:14:45.341531: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-17 16:14:45.343004: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-17 16:14:45.491259: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-17 16:14:45.493451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.7934734513274336\n",
      "\n",
      "f1 score :  0.6235634115195914\n",
      "roc-auc score :  0.7861590479904785\n",
      "[[16880  4239]\n",
      " [ 1362  4639]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86     21119\n",
      "         1.0       0.52      0.77      0.62      6001\n",
      "\n",
      "    accuracy                           0.79     27120\n",
      "   macro avg       0.72      0.79      0.74     27120\n",
      "weighted avg       0.84      0.79      0.81     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.7923672566371681\n",
      "\n",
      "f1 score :  0.621496269409155\n",
      "roc-auc score :  0.784494481754501\n",
      "[[16866  4253]\n",
      " [ 1378  4623]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.80      0.86     21119\n",
      "         1.0       0.52      0.77      0.62      6001\n",
      "\n",
      "    accuracy                           0.79     27120\n",
      "   macro avg       0.72      0.78      0.74     27120\n",
      "weighted avg       0.84      0.79      0.80     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = SMOTE(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion : les stratégie d'undersampling est la plus efficace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - test différence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.7932890855457227\n",
      "\n",
      "f1 score :  0.6232020432853879\n",
      "roc-auc score :  0.7858617389233682\n",
      "[[16878  4241]\n",
      " [ 1365  4636]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86     21119\n",
      "         1.0       0.52      0.77      0.62      6001\n",
      "\n",
      "    accuracy                           0.79     27120\n",
      "   macro avg       0.72      0.79      0.74     27120\n",
      "weighted avg       0.84      0.79      0.81     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegressionCV(max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.782853982300885\n",
      "\n",
      "f1 score :  0.6125912768896783\n",
      "roc-auc score :  0.7803544927432466\n",
      "[[16575  4544]\n",
      " [ 1345  4656]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.78      0.85     21119\n",
      "         1.0       0.51      0.78      0.61      6001\n",
      "\n",
      "    accuracy                           0.78     27120\n",
      "   macro avg       0.72      0.78      0.73     27120\n",
      "weighted avg       0.83      0.78      0.80     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = SGDClassifier(max_iter = 2000, n_jobs = -1)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8164454277286136\n",
      "\n",
      "f1 score :  0.6619125237707145\n",
      "roc-auc score :  0.8148655149012011\n",
      "[[17269  3850]\n",
      " [ 1128  4873]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.82      0.87     21119\n",
      "         1.0       0.56      0.81      0.66      6001\n",
      "\n",
      "    accuracy                           0.82     27120\n",
      "   macro avg       0.75      0.81      0.77     27120\n",
      "weighted avg       0.85      0.82      0.83     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion : on va partir sur un RandomForrestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - exploration des hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8692109144542773\n",
      "\n",
      "f1 score :  0.671175762068007\n",
      "roc-auc score :  0.7740828609629506\n",
      "[[19949  1170]\n",
      " [ 2379  3622]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.94      0.92     21119\n",
      "         1.0       0.76      0.60      0.67      6001\n",
      "\n",
      "    accuracy                           0.87     27120\n",
      "   macro avg       0.82      0.77      0.79     27120\n",
      "weighted avg       0.86      0.87      0.86     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_s, y_train_s = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators = 200,\n",
    "    max_features = 'sqrt',\n",
    "    criterion = 'entropy',\n",
    "    max_depth = 30,\n",
    "    bootstrap = False,\n",
    "    min_samples_split = 5,\n",
    "    min_samples_leaf = 2,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# essai de modelisation par ville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sydney = df[df['Location'] == 'Sydney']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed',\n",
      "       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
      "       'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm', 'RainToday',\n",
      "       'RainTomorrow', 'WindGustDir_cos', 'WindGustDir_sin', 'WindDir9am_cos',\n",
      "       'WindDir9am_sin', 'WindDir3pm_cos', 'WindDir3pm_sin', 'Month_cos',\n",
      "       'Month_sin', 'Season_cos', 'Season_sin', 'Climate_Desert',\n",
      "       'Climate_Grassland', 'Climate_Subtropical', 'Climate_Temperate',\n",
      "       'Climate_Tropical', 'Year_2007', 'Year_2008', 'Year_2009', 'Year_2010',\n",
      "       'Year_2011', 'Year_2012', 'Year_2013', 'Year_2014', 'Year_2015',\n",
      "       'Year_2016', 'Year_2017', 'sin_lat', 'cos_lat', 'sin_lon', 'cos_lon'],\n",
      "      dtype='object')\n",
      "\n",
      "(3337, 46)\n",
      "\n",
      "RainTomorrow\n",
      "0.0    0.740785\n",
      "1.0    0.259215\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_sydney.columns, end = '\\n\\n')\n",
    "print(df_sydney.shape, end = '\\n\\n')\n",
    "print(df_sydney['RainTomorrow'].value_counts(normalize = True))\n",
    "\n",
    "df_sydney = df_sydney.drop(columns = ['Date', 'Location', 'sin_lat', 'cos_lat', 'sin_lon', 'cos_lon',\n",
    "                  'Climate_Desert','Climate_Grassland', 'Climate_Subtropical',\n",
    "                  'Climate_Temperate', 'Climate_Tropical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy : 0.8577844311377245\n",
      "f1 score :  0.6905537459283387\n",
      "roc-auc score :  0.7780755532200619\n",
      "[[467  28]\n",
      " [ 67 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.94      0.91       495\n",
      "         1.0       0.79      0.61      0.69       173\n",
      "\n",
      "    accuracy                           0.86       668\n",
      "   macro avg       0.83      0.78      0.80       668\n",
      "weighted avg       0.85      0.86      0.85       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_sydney.drop(columns = 'RainTomorrow')\n",
    "y = df_sydney['RainTomorrow']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2, stratify = y)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 10000, verbose = 1)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('score accuracy :', model.score(X_test_scaled, y_test))\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy : 0.8293413173652695\n",
      "f1 score :  0.7076923076923077\n",
      "roc-auc score :  0.8190459508378584\n",
      "[[416  79]\n",
      " [ 35 138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88       495\n",
      "         1.0       0.64      0.80      0.71       173\n",
      "\n",
      "    accuracy                           0.83       668\n",
      "   macro avg       0.78      0.82      0.79       668\n",
      "weighted avg       0.85      0.83      0.83       668\n",
      "\n",
      "après essai sur grid search, le modele simple de regressionlogicitc est le meilleur\n"
     ]
    }
   ],
   "source": [
    "X = df_sydney.drop(columns = 'RainTomorrow')\n",
    "y = df_sydney['RainTomorrow']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2, stratify = y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 10000, verbose = 1, class_weight = {0 : 0.26, 1 : 0.74})\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('score accuracy :', model.score(X_test_scaled, y_test))\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "print('après essai sur grid search, le modele simple de regressionlogicitc est le meilleur')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essai avec date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RainTomorrow\n",
      "0.0    0.740785\n",
      "1.0    0.259215\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_sydney = df[df['Location'] == 'Sydney']\n",
    "\n",
    "df_sydney = df_sydney.set_index('Date')\n",
    "\n",
    "df_sydney = df_sydney.drop(columns = ['Location', 'sin_lat', 'cos_lat', 'sin_lon', 'cos_lon',\n",
    "                  'Climate_Desert','Climate_Grassland', 'Climate_Subtropical',\n",
    "                  'Climate_Temperate', 'Climate_Tropical'])\n",
    "\n",
    "print(df_sydney['RainTomorrow'].value_counts(normalize = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy : 0.8308383233532934\n",
      "f1 score :  0.710997442455243\n",
      "roc-auc score :  0.821936124248263\n",
      "[[416  79]\n",
      " [ 34 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88       495\n",
      "         1.0       0.64      0.80      0.71       173\n",
      "\n",
      "    accuracy                           0.83       668\n",
      "   macro avg       0.78      0.82      0.80       668\n",
      "weighted avg       0.85      0.83      0.84       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_sydney.drop(columns = 'RainTomorrow')\n",
    "y = df_sydney['RainTomorrow']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2, stratify = y)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 10000, verbose = 1, class_weight = 'balanced')\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('score accuracy :', model.score(X_test_scaled, y_test))\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RainTomorrow\n",
      "0.0    0.741948\n",
      "1.0    0.258052\n",
      "Name: proportion, dtype: float64\n",
      "RainTomorrow\n",
      "0.0    0.736132\n",
      "1.0    0.263868\n",
      "Name: proportion, dtype: float64\n",
      "score accuracy : 0.815592203898051\n",
      "f1 score :  0.48535564853556484\n",
      "roc-auc score :  0.6596810775782262\n",
      "[[486   5]\n",
      " [118  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.99      0.89       491\n",
      "         1.0       0.92      0.33      0.49       176\n",
      "\n",
      "    accuracy                           0.82       667\n",
      "   macro avg       0.86      0.66      0.69       667\n",
      "weighted avg       0.84      0.82      0.78       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_sydney.drop(columns = 'RainTomorrow')\n",
    "y = df_sydney['RainTomorrow']\n",
    "\n",
    "cut_index = df_sydney.index[int(0.8 * len(df_sydney))]  # 80% des données pour l'entraînement\n",
    "\n",
    "    # Diviser les données en fonction de la date\n",
    "X_train = X[df_sydney.index <= cut_index]\n",
    "y_train = y[df_sydney.index <= cut_index]\n",
    "X_test = X[df_sydney.index > cut_index]\n",
    "y_test = y[df_sydney.index > cut_index]\n",
    "\n",
    "print(y_train.value_counts(normalize = True))\n",
    "print(y_test.value_counts(normalize = True))\n",
    "\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 10000, verbose = 1, class_weight = {0 : 0.73, 1 : 0.27})\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('score accuracy :', model.score(X_test_scaled, y_test))\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END bootstrap=False, criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=924; total time=   8.6s\n",
      "[CV] END bootstrap=False, criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=924; total time=   8.7s\n",
      "[CV] END bootstrap=False, criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=924; total time=   8.7s\n",
      "[CV] END bootstrap=False, criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=924; total time=   8.8s\n",
      "[CV] END bootstrap=False, criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=924; total time=   8.8s\n",
      "best_estimator :  RandomForestClassifier(bootstrap=False, class_weight={0: 4, 1: 1},\n",
      "                       criterion='log_loss', max_depth=30, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=7,\n",
      "                       n_estimators=924, n_jobs=-1)\n",
      "best_params : {'bootstrap': False, 'criterion': 'log_loss', 'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 924}\n",
      "score accuracy : 0.38636363636363635\n",
      "f1 score :  0.5396825396825397\n",
      "roc-auc score :  0.6850351786706164\n",
      "[[483   8]\n",
      " [108  68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.98      0.89       491\n",
      "         1.0       0.89      0.39      0.54       176\n",
      "\n",
      "    accuracy                           0.83       667\n",
      "   macro avg       0.86      0.69      0.72       667\n",
      "weighted avg       0.84      0.83      0.80       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model =RandomForestClassifier( n_jobs = -1, class_weight = {0 : 4, 1 : 1})\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1, verbose = 2, scoring = 'recall')\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('best_estimator : ', grid_search.best_estimator_)\n",
    "print('best_params :', grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test_scaled)\n",
    "\n",
    "print('score accuracy :', grid_search.score(X_test_scaled, y_test))\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meteo-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
